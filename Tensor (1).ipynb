{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da4b583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import torch and other required modules\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e26a736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84344058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([8], shape=(1,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#scalar\n",
    "a=tf.random.uniform(shape=[1], minval=5, maxval=10, dtype=tf.int64)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a50df32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([9 9], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#vector\n",
    "a=tf.random.uniform(shape=[2], minval=5, maxval=10, dtype=tf.int64)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff436c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[6 9]\n",
      " [9 5]], shape=(2, 2), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#matrix\n",
    "a=tf.random.uniform(shape=[2,2], minval=5, maxval=10, dtype=tf.int64)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c57baa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[9 6]\n",
      "  [6 7]]\n",
      "\n",
      " [[5 6]\n",
      "  [9 9]]], shape=(2, 2, 2), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#tensor n*n*n matrix\n",
    "a=tf.random.uniform(shape=[2,2,2], minval=5, maxval=10, dtype=tf.int64)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d2c68",
   "metadata": {},
   "source": [
    "# simple operation using tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18368911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Get the rank of the tensor\n",
    "tensorA = tf.constant([[1, 2], [3, 4], [5, 6]]);\n",
    "rank = tf.rank(tensorA)\n",
    "print(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94d0097",
   "metadata": {},
   "source": [
    "ALL bascic arthemathic opertation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "228801d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(2)\n",
    "b = tf.constant(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aea050ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Addition\n",
    "c = tf.add(a, b)\n",
    "\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7122375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Subtraction\n",
    "d = tf.subtract(a, b)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2e1e6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Multiplication\n",
    "e = tf.multiply(a, b)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3606e7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.6666666666666666, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Division\n",
    "f = tf.divide(a, b)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "696c4ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 1]\n",
      " [5 2]\n",
      " [8 3]], shape=(3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#Tensor Addition\n",
    "tensorA = tf.constant([[1, 2], [3, 4], [5, 6]]);\n",
    "tensorB = tf.constant([[1,-1], [2,-2], [3,-3]]);\n",
    "\n",
    "tensorNew = tf.add(tensorA,tensorB)\n",
    "\n",
    "print(tensorNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41f3afa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 3]\n",
      " [1 6]\n",
      " [2 9]], shape=(3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#Tensor Subtraction\n",
    "tensorA = tf.constant([[1, 2], [3, 4], [5, 6]]);\n",
    "tensorB = tf.constant([[1,-1], [2,-2], [3,-3]]);\n",
    "\n",
    "\n",
    "tensorNew = tf.subtract(tensorA,tensorB);\n",
    "print(tensorNew)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c109bc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([4 8 6 8], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#Tensor Multiplication\n",
    "tensorA = tf.constant([1, 2, 3, 4]);\n",
    "tensorB = tf.constant([4, 4, 2, 2]);\n",
    "\n",
    "\n",
    "tensorNew = tf.multiply(tensorA,tensorB)\n",
    "print(tensorNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "103d0c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1 -2]\n",
      " [ 6 -8]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#Tensor Multiplication\n",
    "#this not matrix multiplication its element wise multiplication\n",
    "tensorA = tf.constant([[1, 2], [3, 4]]);\n",
    "tensorB = tf.constant([[1,-1], [2,-2]]);\n",
    "\n",
    "\n",
    "tensorNew = tf.multiply(tensorA,tensorB)\n",
    "print(tensorNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "544cbae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2. 2. 3. 4.], shape=(4,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "#Tensor Division\n",
    "tensorA = tf.constant([2, 4, 6, 8]);\n",
    "tensorB = tf.constant([1, 2, 2, 2]);\n",
    "\n",
    "\n",
    "tensorNew = tf.divide(tensorA, tensorB);\n",
    "print(tensorNew)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e58cbe",
   "metadata": {},
   "source": [
    "tensor reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9360d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]], shape=(4, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tensorA = tf.constant([[1, 2], [3, 4]]);\n",
    "tensorB = tf.reshape(tensorA,[4, 1]);\n",
    "print(tensorB )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2fe7180e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1 2 3 4]], shape=(1, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tensorA = tf.constant([[1, 2], [3, 4]]);\n",
    "tensorB = tf.reshape(tensorA,[1,4]);\n",
    "print(tensorB )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e738b92",
   "metadata": {},
   "source": [
    "# variable and constand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a579c7e",
   "metadata": {},
   "source": [
    "VARIABLE\n",
    "TensorFlow variables are typically used to store model parameters, such as weights and biases, which are adjusted during the training process to improve model performance. In other words, variables are used to store values that change during the execution of the graph.\n",
    "\n",
    "For example, in a neural network model, the weights and biases are adjusted during the training process to minimize the loss function. We can use TensorFlow variables to store these values and update them during each iteration of the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80a9cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable tensor\n",
    "b = tf.Variable([4, 5, 6])\n",
    "#In the above code, b is a variable tensor with initial values [4, 5, 6]. \n",
    "#Unlike constants, variables can be modified using operations like assignment (tf.assign()) or \n",
    "#through the training process by optimizers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d844a81",
   "metadata": {},
   "source": [
    "CONSTAND\n",
    "TensorFlow constants are typically used to store input data or other fixed values that are used in the model. In other words, constants are used to store values that remain constant throughout the execution of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff801269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a constant tensor\n",
    "a = tf.constant([1, 2, 3])\n",
    "#In the above code, a is a constant tensor with values [1, 2, 3]. \n",
    "#The values of constants cannot be modified once they are defined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447d077f",
   "metadata": {},
   "source": [
    "We saw that TensorFlow variables are used to store values that change during the execution of the graph,\n",
    "such as model parameters and stateful operations, while TensorFlow constants are used to store values that remain constant throughout the execution of the graph, \n",
    "such as input data and other fixed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebed926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a placeholder\n",
    "a = tf.placeholder(tf.float32, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd97d5c",
   "metadata": {},
   "source": [
    "#loss functions\n",
    "\n",
    "Categorical crossentropy is a commonly used loss function in multi-class classification tasks. \n",
    "It measures the dissimilarity between the predicted probability distribution and the true one-hot encoded labels.\n",
    "\n",
    "Sparse categorical crossentropy is a loss function commonly used in multi-class classification tasks where the true labels are integers instead of one-hot encoded vectors. \n",
    "It computes the crossentropy loss between the predicted probability distribution and the true integer labels.\n",
    "\n",
    "\n",
    "Kullback-Leibler (KL) divergence, also known as relative entropy, is a measure of the difference between two probability distributions. \n",
    "In the context of machine learning, it is often used as a loss function to compare predicted probability distributions\n",
    "with true probability distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e3250b",
   "metadata": {},
   "source": [
    "Regression Tasks:\n",
    "\n",
    "Mean Squared Error (MSE): Measures the average squared difference between predicted and true values.\n",
    "Mean Absolute Error (MAE): Computes the average absolute difference between predicted and true values.\n",
    "Huber Loss: Combines the advantages of MSE and MAE, providing a more robust loss function that is less sensitive to outliers.\n",
    "Binary Classification:\n",
    "\n",
    "Binary Crossentropy: Measures the dissimilarity between the predicted probabilities and the true binary labels.\n",
    "Hinge Loss: Suitable for SVM-based classifiers, penalizes misclassified samples.\n",
    "Log Loss: Computes the logarithm of the predicted probabilities for binary classification tasks.\n",
    "Multi-class Classification:\n",
    "\n",
    "Categorical Crossentropy: Evaluates the difference between predicted probabilities and true class labels for multi-class classification.\n",
    "Sparse Categorical Crossentropy: Similar to categorical crossentropy, but expects integer target labels instead of one-hot encoded vectors.\n",
    "Kullback-Leibler Divergence: Measures the divergence between predicted and true probability distributions.\n",
    "Sequence Generation:\n",
    "\n",
    "Connectionist Temporal Classification (CTC) Loss: Used for tasks like speech recognition, it handles variable-length sequences and alignment between inputs and targets.\n",
    "Object Detection:\n",
    "\n",
    "Intersection over Union (IoU): Measures the overlap between predicted and true bounding boxes.\n",
    "Mean Average Precision (mAP): Evaluates the precision and recall of object detection models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4929c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIMZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4ccde8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6206e572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\91964\\tensorflow_datasets\\tf_flowers\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36bdfd1093c4e4d8e16c8328022fe1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc3acb2778c40f4bc6e78fa65d19825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\91964\\tensorflow_datasets\\tf_flowers\\3.0.1.incompleteU2SQF0\\tf_flowers-train.tfrecord*...: …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset tf_flowers downloaded and prepared to C:\\Users\\91964\\tensorflow_datasets\\tf_flowers\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "## Loading images and labels\n",
    "(train_ds, train_labels), (test_ds, test_labels) = tfds.load(\n",
    "    \"tf_flowers\",\n",
    "    split=[\"train[:70%]\", \"train[:30%]\"], ## Train test split\n",
    "    batch_size=-1,\n",
    "    as_supervised=True,  # Include labels\n",
    ")\n",
    "\n",
    "## Resizing images\n",
    "train_ds = tf.image.resize(train_ds, (150, 150))\n",
    "test_ds = tf.image.resize(test_ds, (150, 150))\n",
    "\n",
    "## Transforming labels to correct format\n",
    "train_labels = to_categorical(train_labels, num_classes=5)\n",
    "test_labels = to_categorical(test_labels, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5499703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 6s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#https://www.geeksforgeeks.org/vgg-16-cnn-model/\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "## Loading VGG16 model\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=train_ds[0].shape)\n",
    "base_model.trainable = False ## Not trainable weights\n",
    "\n",
    "## Preprocessing input\n",
    "train_ds = preprocess_input(train_ds) \n",
    "test_ds = preprocess_input(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e280b60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68196c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "flatten_layer = layers.Flatten()\n",
    "dense_layer_1 = layers.Dense(50, activation='relu')\n",
    "dense_layer_2 = layers.Dense(20, activation='relu')\n",
    "prediction_layer = layers.Dense(5, activation='softmax')\n",
    "\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    flatten_layer,\n",
    "    dense_layer_1,\n",
    "    dense_layer_2,\n",
    "    prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "504c5808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "65/65 [==============================] - 556s 9s/step - loss: 0.8868 - accuracy: 0.6818 - val_loss: 0.9846 - val_accuracy: 0.6518\n",
      "Epoch 2/5\n",
      "65/65 [==============================] - 535s 8s/step - loss: 0.6035 - accuracy: 0.7766 - val_loss: 1.0780 - val_accuracy: 0.6693\n",
      "Epoch 3/5\n",
      "65/65 [==============================] - 540s 8s/step - loss: 0.4015 - accuracy: 0.8477 - val_loss: 0.9721 - val_accuracy: 0.6732\n",
      "Epoch 4/5\n",
      "65/65 [==============================] - 555s 9s/step - loss: 0.3334 - accuracy: 0.8706 - val_loss: 0.9676 - val_accuracy: 0.7004\n",
      "Epoch 5/5\n",
      "65/65 [==============================] - 503s 8s/step - loss: 0.2278 - accuracy: 0.9148 - val_loss: 1.0065 - val_accuracy: 0.7160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20510cfd060>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n",
    "\n",
    "model.fit(train_ds, train_labels, epochs=5, validation_split=0.2, batch_size=32, callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "461ac770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "65/65 [==============================] - 77s 1s/step - loss: 1.5236 - accuracy: 0.3114 - val_loss: 1.3706 - val_accuracy: 0.4261\n",
      "Epoch 2/5\n",
      "65/65 [==============================] - 67s 1s/step - loss: 1.3236 - accuracy: 0.4209 - val_loss: 1.2906 - val_accuracy: 0.4163\n",
      "Epoch 3/5\n",
      "65/65 [==============================] - 75s 1s/step - loss: 1.2150 - accuracy: 0.4827 - val_loss: 1.1854 - val_accuracy: 0.4922\n",
      "Epoch 4/5\n",
      "65/65 [==============================] - 69s 1s/step - loss: 1.1296 - accuracy: 0.5275 - val_loss: 1.2471 - val_accuracy: 0.4747\n",
      "Epoch 5/5\n",
      "65/65 [==============================] - 79s 1s/step - loss: 1.0806 - accuracy: 0.5509 - val_loss: 1.1140 - val_accuracy: 0.5292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20511d4ecb0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #hands on image classification\n",
    "# from tensorflow.keras import Sequential, layers\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "\n",
    "# hand_made_model = Sequential()\n",
    "# hand_made_model.add(Rescaling(1./255, input_shape=(150,150,3)))\n",
    "\n",
    "# hand_made_model.add(layers.Conv2D(16, kernel_size=10, activation='relu'))\n",
    "# hand_made_model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "# hand_made_model.add(layers.Conv2D(32, kernel_size=8, activation=\"relu\"))\n",
    "# hand_made_model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "# hand_made_model.add(layers.Conv2D(32, kernel_size=6, activation=\"relu\"))\n",
    "# hand_made_model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "# hand_made_model.add(layers.Flatten())\n",
    "# hand_made_model.add(layers.Dense(50, activation='relu'))\n",
    "# hand_made_model.add(layers.Dense(20, activation='relu'))\n",
    "# hand_made_model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "# hand_made_model.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='categorical_crossentropy',\n",
    "#     metrics=['accuracy'],\n",
    "# )\n",
    "\n",
    "\n",
    "# es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n",
    "\n",
    "# hand_made_model.fit(train_ds, train_labels, epochs=5, validation_split=0.2, batch_size=32, callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f98b7be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 324s 9s/step - loss: 0.1865 - accuracy: 0.9373\n",
      "Test Loss: 0.18648457527160645\n",
      "Test Accuracy: 0.9373297095298767\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_ds, test_labels)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950edda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e61defd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53105550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1101, 150, 150, 3), dtype=float32, numpy=\n",
       "array([[[[-6.84166870e+01,  1.53410110e+01, -1.78466644e+01],\n",
       "         [-6.15640678e+01,  2.19140701e+01, -8.05359650e+00],\n",
       "         [-7.29496689e+01,  8.33789062e+00, -2.39697800e+01],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[-6.68862000e+01,  2.42730026e+01, -1.14402771e-01],\n",
       "         [-4.53190041e+01,  3.26026077e+01,  9.54080963e+00],\n",
       "         [-6.34483376e+01,  1.26169968e+01, -2.26906662e+01],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[-7.64754486e+01,  2.28330002e+01,  3.30178070e+00],\n",
       "         [-4.02803345e+01,  3.58623428e+01,  1.36720047e+01],\n",
       "         [-5.20367775e+01,  2.55610123e+01, -8.63999176e+00],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]]],\n",
       "\n",
       "\n",
       "       [[[-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]]],\n",
       "\n",
       "\n",
       "       [[[ 1.06860985e+02,  4.60209885e+01, -2.48799973e+01],\n",
       "         [ 1.14207939e+02,  5.12071304e+01, -1.89736023e+01],\n",
       "         [ 1.22600990e+02,  5.77609940e+01, -1.51666641e+01],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[ 1.08880730e+02,  4.80407333e+01, -2.28602676e+01],\n",
       "         [ 1.19780205e+02,  5.39402084e+01, -1.59608002e+01],\n",
       "         [ 1.23221001e+02,  6.02210007e+01, -1.26800003e+01],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[ 1.13545891e+02,  5.27058945e+01, -1.81951141e+01],\n",
       "         [ 1.19864998e+02,  5.87290115e+01, -1.20733337e+01],\n",
       "         [ 1.26418770e+02,  6.25787735e+01, -7.32221985e+00],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-7.34525986e+01, -7.10861053e+01,  7.08358994e+01],\n",
       "         [-7.52838058e+01, -3.59995270e+01,  8.98877335e+01],\n",
       "         [ 6.40929947e+01,  7.06454544e+01,  7.49795609e+01],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[-9.23203430e+01, -2.20419312e+01,  1.25357338e+02],\n",
       "         [-1.00514206e+02, -8.69981995e+01,  7.86240005e+01],\n",
       "         [ 6.94898224e+00,  4.36900330e+00, -4.19600677e+00],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[-1.02428780e+02, -6.75234528e+01,  1.21718666e+02],\n",
       "         [ 6.13433075e+00,  1.35929947e+01, -1.29333420e+01],\n",
       "         [-4.90279846e+01, -2.93368378e+01,  5.09156418e+01],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]]],\n",
       "\n",
       "\n",
       "       [[[ 9.28903275e+01,  1.04134682e+02,  1.09064980e+02],\n",
       "         [ 7.55919418e+01,  8.47519455e+01,  8.88776016e+01],\n",
       "         [ 8.23481216e+01,  8.85881271e+01,  9.46604538e+01],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[ 8.56545944e+01,  9.56548691e+01,  9.72330704e+01],\n",
       "         [ 8.89186020e+01,  9.86778030e+01,  1.02537605e+02],\n",
       "         [ 9.64689865e+01,  1.05469002e+02,  1.09568001e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[ 4.18401108e+01,  5.89419022e+01,  5.76311111e+01],\n",
       "         [ 5.26796646e+01,  6.62543259e+01,  7.34519882e+01],\n",
       "         [ 5.11165543e+01,  6.57098923e+01,  6.75088882e+01],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]]],\n",
       "\n",
       "\n",
       "       [[[ 1.02028740e+02,  1.03241814e+02,  9.43097763e+01],\n",
       "         [ 1.50048737e+02,  1.37934326e+02,  1.29780273e+02],\n",
       "         [ 1.49061005e+02,  1.38221008e+02,  1.31320007e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[-3.05207062e+00,  5.16279373e+01,  3.56402664e+01],\n",
       "         [ 1.47364197e+02,  1.30860992e+02,  1.24501610e+02],\n",
       "         [ 1.47140991e+02,  1.36300995e+02,  1.29399994e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[-4.73456726e+01,  2.01743393e+01,  1.87333679e+00],\n",
       "         [ 8.71929855e+01,  9.89409866e+01,  8.83013077e+01],\n",
       "         [ 1.45136566e+02,  1.34296570e+02,  1.27395561e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]],\n",
       "\n",
       "        [[-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         ...,\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02],\n",
       "         [-1.03939003e+02, -1.16778999e+02, -1.23680000e+02]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98720d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58552701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633fa613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aec603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "#training_images=training_images/255.0\n",
    "#test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "model.evaluate(test_images, test_labels)\n",
    "classifications = model.predict(test_images)\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca423d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
